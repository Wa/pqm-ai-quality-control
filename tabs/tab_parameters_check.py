"""Streamlit tab for parameters consistency checks."""
from __future__ import annotations

import os
import re
import time
from datetime import datetime
from typing import Iterable

import streamlit as st

from backend_client import get_backend_client, is_backend_available
from config import CONFIG
from util import (
    ensure_session_dirs,
    get_directory_refresh_token,
    handle_file_upload,
    list_directory_contents,
)

from .parameters import PARAMETERS_WORKFLOW_SURFACE, stream_text


def _format_file_size(size_bytes: int) -> str:
    if size_bytes == 0:
        return "0 B"
    size_names = ["B", "KB", "MB", "GB"]
    index = 0
    value = float(size_bytes)
    while value >= 1024 and index < len(size_names) - 1:
        value /= 1024.0
        index += 1
    return f"{value:.1f} {size_names[index]}"


def _format_timestamp(timestamp: float) -> str:
    return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M")


def _truncate_filename(filename: str, max_length: int = 40) -> str:
    if len(filename) <= max_length:
        return filename
    name, ext = os.path.splitext(filename)
    available = max_length - len(ext) - 3
    if available <= 0:
        return filename[: max_length - 3] + "..."
    return name[:available] + "..." + ext


def _collect_files(folder: str) -> list[dict[str, object]]:
    if not folder:
        return []
    token = get_directory_refresh_token(folder)
    entries = [dict(entry) for entry in list_directory_contents(folder, token)]
    for entry in entries:
        entry.setdefault("path", os.path.join(folder, entry["name"]))
    entries.sort(key=lambda item: item["modified"], reverse=True)
    return entries


def _latest_file(paths: Iterable[str]) -> str | None:
    candidates = [p for p in paths if os.path.isfile(p)]
    if not candidates:
        return None
    candidates.sort(key=lambda value: os.path.getmtime(value))
    return candidates[-1]


@st.fragment()
def _render_parameters_file_lists(
    *,
    reference_dir: str,
    target_dir: str,
    graph_dir: str,
    final_results_dir: str,
    session_id: str,
) -> None:
    """Render the right-hand file management column as a fragment."""

    st.subheader("ğŸ“ æ–‡ä»¶ç®¡ç†")

    reference_files = _collect_files(reference_dir)
    target_files = _collect_files(target_dir)
    graph_files = _collect_files(graph_dir)
    result_files = _collect_files(final_results_dir)

    col_clear1, col_clear2, col_clear3, col_clear4 = st.columns(4)
    with col_clear1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºåŸºå‡†æ–‡ä»¶", key=f"parameters_clear_reference_{session_id}"):
            try:
                for info in reference_files:
                    os.remove(info["path"])
                st.success("å·²æ¸…ç©ºåŸºå‡†æ–‡ä»¶")
                st.rerun(scope="fragment")
            except Exception as error:
                st.error(f"æ¸…ç©ºå¤±è´¥: {error}")
    with col_clear2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¾…æ£€æŸ¥", key=f"parameters_clear_target_{session_id}"):
            try:
                for info in target_files:
                    os.remove(info["path"])
                st.success("å·²æ¸…ç©ºå¾…æ£€æŸ¥æ–‡ä»¶")
                st.rerun(scope="fragment")
            except Exception as error:
                st.error(f"æ¸…ç©ºå¤±è´¥: {error}")
    with col_clear3:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå›¾çº¸", key=f"parameters_clear_graph_{session_id}"):
            try:
                for info in graph_files:
                    os.remove(info["path"])
                st.success("å·²æ¸…ç©ºå›¾çº¸æ–‡ä»¶")
                st.rerun(scope="fragment")
            except Exception as error:
                st.error(f"æ¸…ç©ºå¤±è´¥: {error}")
    with col_clear4:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºç»“æœ", key=f"parameters_clear_results_{session_id}"):
            try:
                for info in result_files:
                    os.remove(info["path"])
                st.success("å·²æ¸…ç©ºåˆ†æç»“æœ")
                st.rerun(scope="fragment")
            except Exception as error:
                st.error(f"æ¸…ç©ºå¤±è´¥: {error}")

    tab_reference, tab_target, tab_graph, tab_results = st.tabs([
        "åŸºå‡†æ–‡ä»¶",
        "å¾…æ£€æŸ¥æ–‡ä»¶",
        "å›¾çº¸æ–‡ä»¶",
        "åˆ†æç»“æœ",
    ])

    def _render_file_list(tab, entries, delete_prefix: str) -> None:
        with tab:
            if not entries:
                st.info("æš‚æ— æ–‡ä»¶")
                return
            for info in entries:
                display_name = _truncate_filename(str(info["name"]))
                with st.expander(f"ğŸ“„ {display_name}", expanded=False):
                    col_meta, col_action = st.columns([3, 1])
                    with col_meta:
                        st.write(f"**æ–‡ä»¶åï¼š** {info['name']}")
                        st.write(f"**å¤§å°ï¼š** {_format_file_size(int(info['size']))}")
                        st.write(f"**ä¿®æ”¹æ—¶é—´ï¼š** {_format_timestamp(float(info['modified']))}")
                    with col_action:
                        delete_key = f"{delete_prefix}_{info['name'].replace(' ', '_').replace('.', '_')}_{session_id}"
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=delete_key):
                            try:
                                os.remove(str(info["path"]))
                                st.success(f"å·²åˆ é™¤ {info['name']}")
                                st.rerun(scope="fragment")
                            except Exception as error:
                                st.error(f"åˆ é™¤å¤±è´¥: {error}")

    _render_file_list(tab_reference, reference_files, "parameters_delete_reference")
    _render_file_list(tab_target, target_files, "parameters_delete_target")
    _render_file_list(tab_graph, graph_files, "parameters_delete_graph")
    _render_file_list(tab_results, result_files, "parameters_delete_result")

    st.markdown("---")
    try:
        result_names = os.listdir(final_results_dir)
    except Exception:
        result_names = []
    csv_paths = [os.path.join(final_results_dir, name) for name in result_names if name.lower().endswith(".csv")]
    xlsx_paths = [os.path.join(final_results_dir, name) for name in result_names if name.lower().endswith(".xlsx")]
    latest_csv = _latest_file(csv_paths)
    latest_xlsx = _latest_file(xlsx_paths)
    if latest_csv or latest_xlsx:
        st.markdown("**ä¸‹è½½æœ€æ–°ç»“æœ**")
    if latest_csv:
        with open(latest_csv, "rb") as handle:
            st.download_button(
                label=f"ä¸‹è½½CSVï¼ˆ{os.path.basename(latest_csv)}ï¼‰",
                data=handle.read(),
                file_name=os.path.basename(latest_csv),
                mime="text/csv",
                key=f"parameters_download_csv_{session_id}",
            )
    if latest_xlsx:
        with open(latest_xlsx, "rb") as handle:
            st.download_button(
                label=f"ä¸‹è½½Excelï¼ˆ{os.path.basename(latest_xlsx)}ï¼‰",
                data=handle.read(),
                file_name=os.path.basename(latest_xlsx),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"parameters_download_xlsx_{session_id}",
            )


def render_parameters_check_tab(session_id: str | None) -> None:
    if session_id is None:
        st.warning("è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
        return

    uploads_root = str(CONFIG["directories"]["uploads"])
    parameters_base = os.path.join(uploads_root, "{session_id}", "parameters")
    base_dirs = {
        "reference": os.path.join(parameters_base, "reference"),
        "target": os.path.join(parameters_base, "target"),
        "graph": os.path.join(parameters_base, "graph"),
        "generated": str(CONFIG["directories"]["generated_files"]),
    }
    session_dirs = ensure_session_dirs(base_dirs, session_id)
    try:
        paths = PARAMETERS_WORKFLOW_SURFACE.prepare_paths(session_dirs)
    except KeyError as error:
        st.error(f"åˆå§‹åŒ–ä¼šè¯ç›®å½•å¤±è´¥ï¼š{error}")
        return

    reference_dir = paths.standards_dir or session_dirs.get("reference", "")
    target_dir = paths.examined_dir or session_dirs.get("target", "")
    graph_dir = session_dirs.get("graph", "")
    parameters_out_root = paths.output_root
    initial_results_dir = paths.initial_results_dir
    final_results_dir = paths.final_results_dir
    checkpoint_dir = paths.checkpoint_dir

    backend_ready = is_backend_available()
    backend_client = get_backend_client() if backend_ready else None
    job_state_key = f"parameters_job_id_{session_id}"
    last_status_key = f"parameters_last_status_{session_id}"
    stream_state_key = f"parameters_stream_state_{session_id}"
    job_status: dict[str, object] | None = None
    job_error: str | None = None

    stored_job_id = st.session_state.get(job_state_key)

    if backend_ready and backend_client is not None:
        if stored_job_id:
            result = backend_client.get_parameters_job(stored_job_id)
            if isinstance(result, dict) and result.get("job_id"):
                job_status = result
            elif isinstance(result, dict) and result.get("status") == "error":
                job_error = str(result.get("message", "åå°ä»»åŠ¡æŸ¥è¯¢å¤±è´¥"))
            elif isinstance(result, dict) and result.get("detail"):
                job_error = str(result.get("detail"))
                if result.get("detail") == "æœªæ‰¾åˆ°ä»»åŠ¡":
                    st.session_state.pop(job_state_key, None)
        if job_status is None:
            result = backend_client.list_parameters_jobs(session_id)
            if isinstance(result, list) and result:
                job_status = result[0]
                if isinstance(job_status, dict) and job_status.get("job_id"):
                    st.session_state[job_state_key] = job_status.get("job_id")
                    stored_job_id = job_status.get("job_id")
            elif isinstance(result, dict) and result.get("status") == "error":
                job_error = str(result.get("message", "åå°ä»»åŠ¡åˆ—è¡¨æŸ¥è¯¢å¤±è´¥"))
    else:
        job_error = "åå°æœåŠ¡æœªè¿æ¥"

    if job_status:
        st.session_state[last_status_key] = job_status
    elif stored_job_id:
        cached_status = st.session_state.get(last_status_key)
        if isinstance(cached_status, dict):
            job_status = cached_status
            job_error = None
    else:
        st.session_state.pop(last_status_key, None)

    status_str = str(job_status.get("status")) if job_status else ""
    job_running = bool(job_status and status_str in {"queued", "running"})
    job_paused = bool(job_status and status_str == "paused")

    col_main, col_info = st.columns([2, 1])

    with col_info:
        _render_parameters_file_lists(
            reference_dir=reference_dir,
            target_dir=target_dir,
            graph_dir=graph_dir,
            final_results_dir=final_results_dir,
            session_id=session_id,
        )

    with col_main:
        st.subheader("âš™ï¸ å‚æ•°ä¸€è‡´æ€§æ£€æŸ¥")
        st.markdown(
            "ç¬¬1æ­¥ï¼šåœ¨å³ä¾§æ–‡ä»¶åˆ—è¡¨ä¸­æ¸…ç†ä¸Šä¸€è½®ä»»åŠ¡é—ç•™çš„æ–‡ä»¶ã€‚  \n"
            "ç¬¬2æ­¥ï¼šåœ¨ä¸‹æ–¹ä¸Šä¼ æœ¬æ¬¡éœ€è¦æ¯”å¯¹çš„åŸºå‡†ã€å¾…æ£€æŸ¥å’Œå›¾çº¸æ–‡ä»¶ã€‚  \n"
            "ç¬¬3æ­¥ï¼šä½¿ç”¨ä¸‹æ–¹çš„æ§åˆ¶æŒ‰é’®å¯åŠ¨æˆ–ç®¡ç†ä»»åŠ¡å¹¶å…³æ³¨è¿›åº¦æç¤ºã€‚  \n"
            "ç¬¬4æ­¥ï¼šä»»åŠ¡ç»“æŸååœ¨å³ä¾§çš„åˆ†æç»“æœåˆ—è¡¨ä¸­ä¸‹è½½è¾“å‡ºæ–‡ä»¶ã€‚  \n"
        )

        st.markdown("**ä¸Šä¼ æ–‡ä»¶**")
        col_reference, col_target = st.columns(2)
        with col_reference:
            reference_uploads = st.file_uploader(
                "ä¸Šä¼ åŸºå‡†æ–‡ä»¶",
                type=None,
                accept_multiple_files=True,
                key=f"parameters_reference_uploader_{session_id}",
            )
            if reference_uploads:
                handle_file_upload(reference_uploads, reference_dir)
                st.success(f"å·²ä¸Šä¼  {len(reference_uploads)} ä»½åŸºå‡†æ–‡ä»¶")
        with col_target:
            target_uploads = st.file_uploader(
                "ä¸Šä¼ å¾…æ£€æŸ¥æ–‡ä»¶",
                type=None,
                accept_multiple_files=True,
                key=f"parameters_target_uploader_{session_id}",
            )
            if target_uploads:
                handle_file_upload(target_uploads, target_dir)
                st.success(f"å·²ä¸Šä¼  {len(target_uploads)} ä»½å¾…æ£€æŸ¥æ–‡ä»¶")

        graph_uploads = st.file_uploader(
            "ä¸Šä¼ å›¾çº¸æ–‡ä»¶",
            type=None,
            accept_multiple_files=True,
            key=f"parameters_graph_uploader_{session_id}",
        )
        if graph_uploads and graph_dir:
            handle_file_upload(graph_uploads, graph_dir)
            st.success(f"å·²ä¸Šä¼  {len(graph_uploads)} ä»½å›¾çº¸æ–‡ä»¶")
        elif graph_uploads:
            st.warning("æœªé…ç½®å›¾çº¸ç›®å½•ï¼Œæ— æ³•ä¿å­˜å›¾çº¸æ–‡ä»¶ã€‚")

        st.markdown("---")

        col_controls = st.container()
        with col_controls:
            col_start, col_pause, col_resume, col_stop = st.columns(4)
            with col_start:
                start_disabled = not backend_ready or job_running or job_paused
                if st.button("â–¶ï¸ å¼€å§‹", disabled=start_disabled, key=f"parameters_start_{session_id}"):
                    if backend_client is not None:
                        result = backend_client.start_parameters_job(session_id)
                        job_id = result.get("job_id") if isinstance(result, dict) else None
                        if not job_id:
                            fallback = backend_client.list_parameters_jobs(session_id)
                            if isinstance(fallback, list) and fallback:
                                latest_job = fallback[0]
                                if isinstance(latest_job, dict) and latest_job.get("job_id"):
                                    job_id = latest_job.get("job_id")
                                    result = latest_job
                        if job_id:
                            st.session_state[job_state_key] = job_id
                            st.success("å·²å¯åŠ¨åå°ä»»åŠ¡")
                            st.rerun()
                        else:
                            message = "ä»»åŠ¡å¯åŠ¨å¤±è´¥"
                            if isinstance(result, dict):
                                message = str(result.get("message", message))
                            st.error(message)
            with col_pause:
                if st.button("â¸ æš‚åœ", disabled=not job_running, key=f"parameters_pause_{session_id}"):
                    if backend_client is not None and job_status:
                        job_id = str(job_status.get("job_id"))
                        backend_client.pause_parameters_job(job_id)
                        st.rerun()
            with col_resume:
                if st.button("â–¶ï¸ ç»§ç»­", disabled=not job_paused, key=f"parameters_resume_{session_id}"):
                    if backend_client is not None and job_status:
                        job_id = str(job_status.get("job_id"))
                        backend_client.resume_parameters_job(job_id)
                        st.rerun()
            with col_stop:
                if st.button("â¹ åœæ­¢", disabled=not (job_running or job_paused), key=f"parameters_stop_{session_id}"):
                    if backend_client is not None and job_status:
                        job_id = str(job_status.get("job_id"))
                        backend_client.stop_parameters_job(job_id)
                        st.rerun()

        st.markdown("---")

        STATUS_LABELS = {
            "queued": "æ’é˜Ÿä¸­",
            "running": "è¿è¡Œä¸­",
            "paused": "å·²æš‚åœ",
            "stopping": "åœæ­¢ä¸­",
            "stopped": "å·²åœæ­¢",
            "succeeded": "å·²å®Œæˆ",
            "finished": "å·²å®Œæˆ",
            "completed": "å·²å®Œæˆ",
            "failed": "å¤±è´¥",
            "error": "å‡ºé”™",
            "canceled": "å·²å–æ¶ˆ",
            "cancelled": "å·²å–æ¶ˆ",
        }
        STAGE_LABELS = {
            "conversion": "æ–‡ä»¶è½¬æ¢",
            "kb_sync": "åŒæ­¥çŸ¥è¯†åº“",
            "warmup": "å‡†å¤‡æ¯”å¯¹",
            "compare": "å‚æ•°æ¯”å¯¹",
            "aggregate": "æ±‡æ€»ç»“æœ",
        }

        if job_status:
            status_label = STATUS_LABELS.get(status_str.lower(), status_str or "æœªçŸ¥çŠ¶æ€")
            st.markdown(f"**ä»»åŠ¡çŠ¶æ€ï¼š** {status_label}")
            stage = job_status.get("stage") or ""
            stage_label = STAGE_LABELS.get(str(stage).lower(), stage)
            if stage_label:
                st.markdown(f"**é˜¶æ®µï¼š** {stage_label}")
            message = job_status.get("message") or ""
            if message:
                st.info(str(message))

            processed = int(job_status.get("processed_chunks") or 0)
            total = int(job_status.get("total_chunks") or 0)
            conversion_weight = 10.0
            bisheng_weight = 85.0
            max_before_results = conversion_weight + bisheng_weight
            stage_name = str(stage).lower()
            status_lower = status_str.lower()
            bisheng_ratio = 0.0
            if total:
                bisheng_ratio = min(max(processed / total, 0.0), 1.0)

            progress_percent = 0.0
            if stage_name == "conversion":
                progress_percent = conversion_weight
            elif stage_name in {"kb_sync", "warmup", "compare", "aggregate"}:
                progress_percent = conversion_weight + bisheng_weight * bisheng_ratio
            else:
                progress_percent = bisheng_weight * bisheng_ratio

            progress_percent = min(progress_percent, max_before_results)

            result_ready = status_lower in {"succeeded", "finished", "completed", "success"}
            if result_ready:
                progress_percent = 100.0

            progress_value = max(0.0, min(progress_percent / 100.0, 1.0))
            progress_label = f"å¤„ç†è¿›åº¦ï¼š{progress_percent:.0f}%"
            st.progress(progress_value, text=progress_label)

            stream_events = job_status.get("stream_events") or []
            if isinstance(stream_events, list):
                stream_state = st.session_state.get(stream_state_key)
                job_id = job_status.get("job_id")
                if not isinstance(stream_state, dict) or stream_state.get("job_id") != job_id:
                    stream_state = {"job_id": job_id, "events": [], "rendered": []}
                stored_events = stream_state.get("events") or []
                known_sequences = {
                    int(event.get("sequence") or 0)
                    for event in stored_events
                    if isinstance(event, dict)
                }
                rendered_raw = stream_state.get("rendered") or []
                rendered_sequences: set[int] = set()
                for value in rendered_raw:
                    try:
                        rendered_sequences.add(int(value))
                    except (TypeError, ValueError):
                        continue
                new_events = []
                for event in stream_events:
                    if not isinstance(event, dict):
                        continue
                    try:
                        sequence = int(event.get("sequence") or 0)
                    except (TypeError, ValueError):
                        sequence = 0
                    if sequence in known_sequences:
                        continue
                    known_sequences.add(sequence)
                    new_events.append(event)
                if new_events:
                    stored_events.extend(new_events)
                    stored_events.sort(key=lambda item: int(item.get("sequence") or 0))
                    stream_state["events"] = stored_events
                    st.session_state[stream_state_key] = stream_state
                elif stream_state.get("events") is None:
                    stream_state["events"] = []
                    st.session_state[stream_state_key] = stream_state

                events_to_render = st.session_state.get(stream_state_key, {}).get("events", [])
                if events_to_render:
                    with st.expander(
                        "ç‚¹å‡»æŸ¥çœ‹å…·ä½“è¿›å±•",
                        expanded=status_str in {"queued", "running"},
                    ):
                        current_group: tuple[str, int] | None = None
                        for event in events_to_render:
                            if not isinstance(event, dict):
                                continue
                            try:
                                sequence = int(event.get("sequence") or 0)
                            except (TypeError, ValueError):
                                sequence = 0
                            kind = event.get("kind")
                            file_name = event.get("file") or ""
                            part = int(event.get("part") or 0)
                            total_parts = int(event.get("total_parts") or 0)
                            timestamp = event.get("ts")
                            message_text = str(event.get("text") or "")
                            if file_name and part:
                                header_key = (file_name, part)
                                if header_key != current_group:
                                    label = f"{file_name} Â· ç¬¬{part}æ®µ"
                                    if total_parts:
                                        label = f"{file_name} Â· ç¬¬{part}/{total_parts}æ®µ"
                                    st.markdown(f"**{label}**")
                                    current_group = header_key
                            role = "user" if kind == "prompt" else "assistant"
                            is_new = sequence not in rendered_sequences
                            with st.chat_message(role):
                                if timestamp:
                                    st.caption(str(timestamp))
                                if message_text:
                                    if is_new:
                                        placeholder = st.empty()
                                        render_method = "text" if role == "user" else "write"
                                        stream_text(
                                            placeholder,
                                            message_text,
                                            render_method=render_method,
                                            delay=0.02,
                                        )
                                    else:
                                        if role == "user":
                                            st.text(message_text)
                                        else:
                                            st.write(message_text)
                                else:
                                    st.write("(æ— å†…å®¹)")
                            rendered_sequences.add(sequence)
                    stream_state["rendered"] = sorted(rendered_sequences)
                    st.session_state[stream_state_key] = stream_state

            logs = job_status.get("logs") or []
            if isinstance(logs, list) and logs:
                with st.expander("åå°æ—¥å¿—", expanded=False):
                    for entry in logs[-50:]:
                        if not isinstance(entry, dict):
                            st.write(entry)
                            continue
                        ts = entry.get("ts") or ""
                        level = entry.get("level") or "info"
                        msg = entry.get("message") or ""
                        st.write(f"[{ts}] {level}: {msg}")
        elif job_error:
            st.warning(job_error)
            st.session_state.pop(stream_state_key, None)
        elif backend_ready:
            st.info("åå°æœåŠ¡å·²è¿æ¥ï¼Œä¸Šä¼ æ–‡ä»¶åç‚¹å‡»å¼€å§‹å³å¯è¿›è¡Œå‚æ•°ä¸€è‡´æ€§æ£€æŸ¥ã€‚")
            st.session_state.pop(stream_state_key, None)
        else:
            st.error("åå°æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            st.session_state.pop(stream_state_key, None)

    if job_running:
        st.caption("é¡µé¢å°†åœ¨ 5 ç§’åè‡ªåŠ¨åˆ·æ–°ä»¥æ›´æ–°åå°ä»»åŠ¡è¿›åº¦â€¦")
        time.sleep(5)
        st.rerun()
