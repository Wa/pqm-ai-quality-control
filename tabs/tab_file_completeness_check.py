import streamlit as st
import os
from util import ensure_session_dirs, handle_file_upload, get_user_session, start_analysis, reset_user_session, complete_analysis, resolve_ollama_host
from config import CONFIG
from ollama import Client as OllamaClient
import openai
import re
import pandas as pd
from datetime import datetime
import json

def parse_llm_table_response(response_text):
    """Parse LLM response to extract table data."""
    if not response_text:
        return []
    # Look for table patterns in the response
    # Common patterns: "åº”åŒ…å«çš„äº¤ä»˜ç‰©æ–‡ä»¶æ¸…å•" followed by "æ˜¯" or "å¦"
    table_data = []
    # Split response into lines and look for table-like patterns
    lines = response_text.split('\n')
    in_table = False
    for line in lines:
        line = line.strip()
        
        # Check if we're entering a table section
        if 'åº”åŒ…å«çš„äº¤ä»˜ç‰©æ–‡ä»¶æ¸…å•' in line and ('å­˜åœ¨' in line or 'æ˜¯' in line or 'å¦' in line):
            in_table = True
            continue
            
        # Skip empty lines and non-table content
        if not line or not in_table:
            continue
            
        # Look for table row patterns
        # Pattern: filename followed by "æ˜¯" or "å¦"
        if '|' in line:
            # Handle pipe-separated format
            parts = [part.strip() for part in line.split('|')]
            if len(parts) >= 2:
                filename = parts[0].strip()
                status = parts[1].strip()
                if filename and status in ['æ˜¯', 'å¦']:
                    table_data.append({'filename': filename, 'status': status})
        else:
            # Handle other formats - look for filename and status
            # Try to find patterns like "filename: æ˜¯" or "filename: å¦"
            status_match = re.search(r'[ï¼š:]\s*(æ˜¯|å¦)', line)
            if status_match:
                status = status_match.group(1)
                filename = line[:status_match.start()].strip()
                if filename:
                    table_data.append({'filename': filename, 'status': status})
    return table_data

def get_stage_requirements(stage_name):
    """Get hardcoded requirements for each stage."""
    stage_requirements = {
        "ç«‹é¡¹é˜¶æ®µ": [
            "é¡¹ç›®ç«‹é¡¹æŠ¥å‘Š", "é¡¹ç›®å¯è¡Œæ€§åˆ†ææŠ¥å‘Š", "é¡¹ç›®é£é™©è¯„ä¼°æŠ¥å‘Š", "é¡¹ç›®è®¡åˆ’ä¹¦",
            "é¡¹ç›®å›¢é˜Ÿç»„å»ºæ–¹æ¡ˆ", "é¡¹ç›®é¢„ç®—æ–¹æ¡ˆ", "é¡¹ç›®æ—¶é—´è®¡åˆ’", "é¡¹ç›®è´¨é‡ç›®æ ‡",
            "é¡¹ç›®æˆæœ¬ç›®æ ‡", "é¡¹ç›®äº¤ä»˜ç‰©æ¸…å•"
        ],
        "Aæ ·é˜¶æ®µ": [
            "ç”µèŠ¯è§„æ ¼ä¹¦", "å°ºå¯¸é“¾å…¬å·®è®¡ç®—ä¹¦", "åˆå§‹DFMEA", "åˆå§‹ç‰¹æ®Šç‰¹æ€§æ¸…å•",
            "ä¸‰æ–°æ¸…å•", "åˆ¶ç¨‹æ ‡å‡†", "å¼€æ¨¡æ¸…å•", "3Dæ•°æ¨¡", "2Då›¾çº¸", "BOMæ¸…å•",
            "ä»¿çœŸæŠ¥å‘Š", "æµ‹è¯•å¤§çº²", "ä¸“åˆ©æŒ–æ˜æ¸…å•", "åˆç‰ˆPFMEA", "äº§çº¿è§„åˆ’æ–¹æ¡ˆ",
            "è¿‡ç¨‹è®¾è®¡åˆå§‹æ–¹æ¡ˆ", "äº§å“å¯åˆ¶é€ æ€§åˆ†æåŠé£é™©åº”å¯¹æŠ¥å‘Š", "åˆå§‹è¿‡ç¨‹æµç¨‹å›¾",
            "åˆå§‹è¿‡ç¨‹ç‰¹æ®Šç‰¹æ€§", "åˆç‰ˆCP", "åˆç‰ˆSOP", "å·¥è‰ºéªŒè¯è®¡åˆ’", "æ ·å“åŒ…è£…æ–¹æ¡ˆ"
        ],
        "Bæ ·é˜¶æ®µ": [
            "è®¾è®¡å˜æ›´å±¥å†è¡¨", "æ›´æ–°ç”µèŠ¯è§„æ ¼ä¹¦", "æ›´æ–°DFMEA", "æ›´æ–°ç‰¹æ®Šç‰¹æ€§æ¸…å•",
            "åˆ¶ç¨‹æ ‡å‡†", "æ›´æ–°3Dæ•°æ¨¡", "æ›´æ–°2Då›¾çº¸", "å°ºå¯¸é“¾å…¬å·®è®¡ç®—ä¹¦",
            "æ›´æ–°BOMæ¸…å•", "æ›´æ–°å¼€æ¨¡æ¸…å•", "æ›´æ–°ä¸‰æ–°æ¸…å•", "ä»¿çœŸæŠ¥å‘Š",
            "DVæµ‹è¯•æŠ¥å‘Š"
        ],
        "Cæ ·é˜¶æ®µ": [
            "æ›´æ–°PFMEA", "é‡äº§äº§çº¿å¼€å‘è¿›å±•æŠ¥å‘Š", "æ›´æ–°æ ·å“åŒ…è£…æ–¹æ¡ˆ",
            "æ›´æ–°è¿‡ç¨‹ç‰¹æ®Šç‰¹æ€§æ¸…å•", "æ›´æ–°CP", "æ›´æ–°SOP", "å·¥è‰ºéªŒè¯è®¡åˆ’",
            "æ ·å“å†å²é—®é¢˜æ¸…å•", "CMKåˆ†ææŠ¥å‘Š", "CPKåˆ†ææŠ¥å‘Š",
            "å·¥ç¨‹å˜æ›´å±¥å†è¡¨", "äº§å“å¯åˆ¶é€ æ€§åˆ†æä¸é£é™©åº”å¯¹æŠ¥å‘Š", "æ›´æ–°è¿‡ç¨‹æµç¨‹å›¾", "æ›´æ–°è¿‡ç¨‹ç‰¹æ®Šç‰¹æ€§æ¸…å•",
            "è®¾å¤‡åœæœºç‡ç»Ÿè®¡è¡¨&è®¾å¤‡æ•…éšœè®°å½•è¡¨", "å·¥è‰ºéªŒè¯æŠ¥å‘Š", "å¤–è§‚æ ‡å‡†ä¹¦", "PVæµ‹è¯•æŠ¥å‘Š"
        ]
    }
    
    return stage_requirements.get(stage_name, [])

def create_completeness_excel(all_stage_data, session_id, generated_session_dir):
    """Create and save Excel file with completeness results in normalized format.
    Columns: [Stage, Deliverable, Exists, FileName, Notes]
    """
    try:
        rows = []
        # Keep a deterministic stage order
        ordered_stages = ['ç«‹é¡¹é˜¶æ®µ', 'Aæ ·é˜¶æ®µ', 'Bæ ·é˜¶æ®µ', 'Cæ ·é˜¶æ®µ']
        for stage_name in ordered_stages:
            for item in all_stage_data.get(stage_name, []):
                rows.append({
                    'Stage': stage_name,
                    'Deliverable': item.get('filename', ''),
                    'Exists': item.get('status', ''),  # 'æ˜¯' / 'å¦'
                    'FileName': item.get('matched_file', ''),
                    'Notes': item.get('note', '')
                })

        df = pd.DataFrame(rows, columns=['Stage', 'Deliverable', 'Exists', 'FileName', 'Notes'])
        
        # Generate timestamped filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"file_completeness_results_{session_id}_{timestamp}.xlsx"
        filepath = os.path.join(generated_session_dir, filename)
        
        # Save to Excel
        df.to_excel(filepath, index=False, engine='openpyxl')
        
        return filepath, filename
        
    except Exception as e:
        st.error(f"Excelå¯¼å‡ºå¤±è´¥: {e}")
        return None, None

def export_completeness_results(session_id, stage_responses, generated_session_dir):
    """Main function to export completeness results to Excel."""
    try:
        all_stage_data = {}
        
        # Process each stage response
        for stage_name, response_text in stage_responses.items():
            if response_text:
                # Prefer strict JSON, fallback to legacy text parsing
                parsed_ok = False
                try:
                    # Try direct JSON first
                    data = json.loads(response_text)
                    if isinstance(data, dict) and isinstance(data.get('items'), list):
                        table_data = []
                        for item in data['items']:
                            name = str(item.get('name', '')).strip()
                            if not name:
                                continue
                            # Robust boolean coercion for various model outputs
                            exists_raw = item.get('exists')
                            if isinstance(exists_raw, bool):
                                exists = exists_raw
                            else:
                                s = str(exists_raw).strip().lower()
                                exists = s in ("true", "1", "yes", "y", "æ˜¯", "å­˜åœ¨")
                            matched_file = str(item.get('matched_file', '') or '').strip()
                            note = str(item.get('note', '') or '').strip()
                            if not exists:
                                matched_file = ''
                            table_data.append({
                                'filename': name,
                                'status': 'æ˜¯' if exists else 'å¦',
                                'matched_file': matched_file,
                                'note': note
                            })
                        all_stage_data[stage_name] = table_data
                        parsed_ok = True
                except Exception:
                    # Try to extract JSON object from code fences or extra text
                    try:
                        # Remove markdown fences if present
                        cleaned = response_text.strip()
                        if cleaned.startswith("```"):
                            cleaned = cleaned.strip('`')
                            idx = cleaned.find("{")
                            if idx >= 0:
                                cleaned = cleaned[idx:]
                        # Fallback: slice first {...} block
                        start = cleaned.find('{')
                        end = cleaned.rfind('}')
                        if start >= 0 and end > start:
                            cleaned = cleaned[start:end+1]
                        data = json.loads(cleaned)
                        if isinstance(data, dict) and isinstance(data.get('items'), list):
                            table_data = []
                            for item in data['items']:
                                name = str(item.get('name', '')).strip()
                                if not name:
                                    continue
                                exists_raw = item.get('exists')
                                if isinstance(exists_raw, bool):
                                    exists = exists_raw
                                else:
                                    s = str(exists_raw).strip().lower()
                                    exists = s in ("true", "1", "yes", "y", "æ˜¯", "å­˜åœ¨")
                                matched_file = str(item.get('matched_file', '') or '').strip()
                                note = str(item.get('note', '') or '').strip()
                                if not exists:
                                    matched_file = ''
                                table_data.append({
                                    'filename': name,
                                    'status': 'æ˜¯' if exists else 'å¦',
                                    'matched_file': matched_file,
                                    'note': note
                                })
                            all_stage_data[stage_name] = table_data
                            parsed_ok = True
                        else:
                            parsed_ok = False
                    except Exception:
                        parsed_ok = False
                
                if not parsed_ok:
                    # Parse LLM response to extract table data (Markdown/loose text)
                    table_data = parse_llm_table_response(response_text)
                    # ensure keys for downstream export
                    for it in table_data:
                        it.setdefault('matched_file', '')
                        it.setdefault('note', '')
                    all_stage_data[stage_name] = table_data
            else:
                # For empty stages, create "å¦" entries for all requirements
                stage_requirements = get_stage_requirements(stage_name)
                all_stage_data[stage_name] = [
                    {'filename': req, 'status': 'å¦', 'matched_file': '', 'note': ''} for req in stage_requirements
                ]
        
        # Create Excel file
        filepath, filename = create_completeness_excel(all_stage_data, session_id, generated_session_dir)
        
        if filepath:
            st.success(f"âœ… æ–‡ä»¶é½å¥—æ€§æ£€æŸ¥ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
            # Display the exported Excel content as a table preview
            try:
                df_preview = pd.read_excel(filepath)
                st.dataframe(df_preview, use_container_width=True)
                # Provide a download button for the exported Excel file
                try:
                    with open(filepath, "rb") as f:
                        file_bytes = f.read()
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½Excelç»“æœ",
                        data=file_bytes,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download_completeness_{session_id}"
                    )
                except Exception as e:
                    st.warning(f"æ— æ³•æä¾›ä¸‹è½½æŒ‰é’®: {e}")
            except Exception as e:
                st.warning(f"æ— æ³•é¢„è§ˆå¯¼å‡ºçš„Excelæ–‡ä»¶: {e}")
            return filepath
        else:
            st.error("âŒ Excelå¯¼å‡ºå¤±è´¥")
            return None
            
    except Exception as e:
        st.error(f"å¯¼å‡ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return None

def generate_stage_prompt(stage_name, stage_folder, stage_requirements):
    """Generate prompt for a specific stage based on requirements and actual files."""
    if not os.path.exists(stage_folder):
        return f"{stage_name}æ–‡ä»¶å¤¹ä¸å­˜åœ¨"
    
    # Get actual files in the stage folder
    actual_files = []
    if os.path.exists(stage_folder):
        files = [f for f in os.listdir(stage_folder) if os.path.isfile(os.path.join(stage_folder, f))]
        actual_files = files
    
    # Create the prompt
    prompt = f"""{stage_name}åº”åŒ…å«çš„æ–‡ä»¶åŒ…æ‹¬
{stage_requirements}

{stage_name}æ–‡ä»¶å¤¹ä¸­å·²æœ‰çš„æ–‡ä»¶æ¸…å•åŒ…æ‹¬
{chr(10).join(actual_files) if actual_files else "ï¼ˆæ— æ–‡ä»¶ï¼‰"}

å¯¹æ¯”{stage_name}åº”åŒ…å«çš„æ–‡ä»¶æ¸…å•å’Œ{stage_name}æ–‡ä»¶å¤¹ä¸­å·²æœ‰çš„æ–‡ä»¶æ¸…å•ï¼ŒåšåŒ¹é…åˆ¤æ–­ï¼ˆå…è®¸åˆç†çš„åç§°è¿‘ä¼¼ï¼Œä¾‹å¦‚â€œå†å²é—®é¢˜è§„é¿æ¸…å•â€â‰ˆâ€œå‰¯æœ¬ LL-lesson learn-å†å²é—®é¢˜è§„é¿-V9.4.xlsxâ€ï¼‰ã€‚

è¯·åªè¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸¥æ ¼ç¬¦åˆä»¥ä¸‹ç»“æ„ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–æ–‡æœ¬ï¼ˆä¸è¦æœ‰è§£é‡Šã€markdownæˆ–å…¶ä»–å­—ç¬¦ï¼‰ï¼š
{{
  "stage": "{stage_name}",
  "items": [
    {{
      "name": "<åº”åŒ…å«çš„äº¤ä»˜ç‰©æ–‡ä»¶å>",
      "exists": true|false,
      "matched_file": "<è‹¥exists=trueï¼Œè¯·å¡«å†™åœ¨è¯¥é˜¶æ®µæ–‡ä»¶å¤¹ä¸­åŒ¹é…åˆ°çš„å®é™…æ–‡ä»¶åï¼›è‹¥ä¸å­˜åœ¨åˆ™å¡«ç©ºå­—ç¬¦ä¸²>",
      "note": "<å¯é€‰ï¼šå…³äºè¯¥è¡Œçš„è¯´æ˜/å¤‡æ³¨ï¼›è‹¥æ— åˆ™å¡«ç©ºå­—ç¬¦ä¸²>"
    }}
    // é’ˆå¯¹åº”åŒ…å«æ¸…å•ä¸­çš„æ¯ä¸€é¡¹éƒ½è¾“å‡ºä¸€æ¡
  ]
}}

è¦æ±‚ï¼š
- itemså¿…é¡»è¦†ç›–â€œåº”åŒ…å«çš„äº¤ä»˜ç‰©æ–‡ä»¶æ¸…å•â€ä¸­çš„æ¯ä¸€é¡¹ï¼Œä¸”åªå‡ºç°ä¸€æ¬¡ï¼›
- existsä¸ºå¸ƒå°”ç±»å‹ï¼›
- ä»…è¾“å‡ºä¸Šè¿°JSONå¯¹è±¡æœ¬èº«ã€‚"""
    
    return prompt

def render_file_completeness_check_tab(session_id):
    # Handle None session_id (user not logged in)
    if session_id is None:
        st.warning("è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
        return
    
    # Page subheader
    st.subheader("ğŸ“ æ–‡ä»¶é½å¥—æ€§æ£€æŸ¥")
    st.markdown("ä¸Šä¼ æ¯ä¸ªé˜¶æ®µçš„æ–‡ä»¶åç‚¹å‡»å¼€å§‹ï¼ŒAIä¼šæ ¹æ®é¢„è®¾çš„æ¸…å•æ£€æŸ¥å¹¶è¾“å‡ºç»“æœï¼Œé¢„è®¾æ¸…å•çš„å…·ä½“æ¡ç›®è§å¸®åŠ©æ–‡æ¡£ã€‚")
    
    # Add CSS to hide chat input (required for auto-scroll to work)
    st.markdown("""
    <style>
    [data-testid="stChatInput"] { display: none; }
    </style>
    """, unsafe_allow_html=True)
    
    
    
    # Define APQP stage directories (with session subfolders) - using centralized config
    base_dir = str(CONFIG["directories"]["apqp_files"])
    base_dirs = {
        "Stage_Initial": os.path.join(base_dir, "Stage_Initial"),
        "Stage_A": os.path.join(base_dir, "Stage_A"),
        "Stage_B": os.path.join(base_dir, "Stage_B"),
        "Stage_C": os.path.join(base_dir, "Stage_C"),
        "generated": str(CONFIG["directories"]["generated_files"])
    }
    session_dirs = ensure_session_dirs(base_dirs, session_id)
    generated_session_dir = session_dirs["generated"]
    completeness_dir = session_dirs.get("generated_file_completeness_check", os.path.join(generated_session_dir, "file_completeness_check"))
    os.makedirs(completeness_dir, exist_ok=True)

    # Get structured user session
    session = get_user_session(session_id, 'completeness')
    
    # Initialize LLM clients
    llm_backend = st.session_state.get(f'llm_backend_{session_id}', 'ollama_9')
    if llm_backend in ("ollama_127","ollama_9"):
        host = resolve_ollama_host(llm_backend)
        ollama_client = OllamaClient(host=host)
    elif llm_backend == "openai":
        openai.api_key = CONFIG["llm"]["openai_api_key"]
        openai.base_url = CONFIG["llm"]["openai_base_url"]

    # Layout: right column for info, left for main content
    col_main, col_info = st.columns([2, 1])

    # Render the info/file column FIRST so file lists appear immediately when demo starts
    with col_info:
        # Early bulk operations: handle clear-all before listing so UI updates immediately
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ–‡ä»¶", key=f"clear_all_files_completeness_{session_id}"):
            try:
                for dir_path in [session_dirs["Stage_Initial"], session_dirs["Stage_A"], session_dirs["Stage_B"], session_dirs["Stage_C"]]:
                    for file in os.listdir(dir_path):
                        file_path = os.path.join(dir_path, file)
                        if os.path.isfile(file_path):
                            os.remove(file_path)
                st.success("å·²æ¸…ç©ºæ‰€æœ‰æ–‡ä»¶")
            except Exception as e:
                st.error(f"æ¸…ç©ºå¤±è´¥: {e}")
        # --- File Manager Module ---
        def get_file_list(folder):
            if not os.path.exists(folder):
                return []
            files = []
            for f in os.listdir(folder):
                file_path = os.path.join(folder, f)
                if os.path.isfile(file_path):
                    stat = os.stat(file_path)
                    files.append({
                        'name': f,
                        'size': stat.st_size,
                        'modified': stat.st_mtime,
                        'path': file_path
                    })
            # Use stable sorting by name first, then by modification time
            return sorted(files, key=lambda x: (x['name'].lower(), x['modified']), reverse=False)

        def format_file_size(size_bytes):
            if size_bytes == 0:
                return "0 B"
            size_names = ["B", "KB", "MB", "GB"]
            i = 0
            while size_bytes >= 1024 and i < len(size_names) - 1:
                size_bytes /= 1024.0
                i += 1
            return f"{size_bytes:.1f} {size_names[i]}"

        def format_timestamp(timestamp):
            from datetime import datetime
            return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M')

        def truncate_filename(filename, max_length=40):
            if len(filename) <= max_length:
                return filename
            name, ext = os.path.splitext(filename)
            available_length = max_length - len(ext) - 3
            if available_length <= 0:
                return filename[:max_length-3] + "..."
            truncated_name = name[:available_length] + "..."
            return truncated_name + ext

        # File Manager Tabs
        tab_initial, tab_a, tab_b, tab_c = st.tabs(["ç«‹é¡¹é˜¶æ®µ", "Aæ ·é˜¶æ®µ", "Bæ ·é˜¶æ®µ", "Cæ ·é˜¶æ®µ"])
        
        with tab_initial:
            initial_files_list = get_file_list(session_dirs["Stage_Initial"])
            if initial_files_list:
                for i, file_info in enumerate(initial_files_list):
                    display_name = truncate_filename(file_info['name'])
                    with st.expander(f"ğŸ“„ {display_name}", expanded=False):
                        col_info, col_action = st.columns([3, 1])
                        with col_info:
                            st.write(f"**æ–‡ä»¶å:** {file_info['name']}")
                            st.write(f"**å¤§å°:** {format_file_size(file_info['size'])}")
                            st.write(f"**ä¿®æ”¹æ—¶é—´:** {format_timestamp(file_info['modified'])}")
                        with col_action:
                            delete_key = f"delete_initial_{file_info['name'].replace(' ', '_').replace('.', '_')}_{session_id}"
                            if st.button("ğŸ—‘ï¸ åˆ é™¤", key=delete_key):
                                try:
                                    os.remove(file_info['path'])
                                    st.success(f"å·²åˆ é™¤: {file_info['name']}")
                                except Exception as e:
                                    st.error(f"åˆ é™¤å¤±è´¥: {e}")
            else:
                st.write("ï¼ˆæœªä¸Šä¼ ï¼‰")
            st.markdown("---")
            st.markdown("**ä¸Šä¼ æ–°æ–‡ä»¶:**")
            new_initial_files = st.file_uploader("é€‰æ‹©ç«‹é¡¹é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key=f"initial_uploader_tab_{session_id}")
            if new_initial_files:
                handle_file_upload(new_initial_files, session_dirs["Stage_Initial"])

        with tab_a:
            a_files_list = get_file_list(session_dirs["Stage_A"])
            if a_files_list:
                for i, file_info in enumerate(a_files_list):
                    display_name = truncate_filename(file_info['name'])
                    with st.expander(f"ğŸ“„ {display_name}", expanded=False):
                        col_info, col_action = st.columns([3, 1])
                        with col_info:
                            st.write(f"**æ–‡ä»¶å:** {file_info['name']}")
                            st.write(f"**å¤§å°:** {format_file_size(file_info['size'])}")
                            st.write(f"**ä¿®æ”¹æ—¶é—´:** {format_timestamp(file_info['modified'])}")
                        with col_action:
                            delete_key = f"delete_a_{file_info['name'].replace(' ', '_').replace('.', '_')}_{session_id}"
                            if st.button("ğŸ—‘ï¸ åˆ é™¤", key=delete_key):
                                try:
                                    os.remove(file_info['path'])
                                    st.success(f"å·²åˆ é™¤: {file_info['name']}")
                                except Exception as e:
                                    st.error(f"åˆ é™¤å¤±è´¥: {e}")
            else:
                st.write("ï¼ˆæœªä¸Šä¼ ï¼‰")
            st.markdown("---")
            st.markdown("**ä¸Šä¼ æ–°æ–‡ä»¶:**")
            new_a_files = st.file_uploader("é€‰æ‹©Aæ ·é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key=f"a_uploader_tab_{session_id}")
            if new_a_files:
                handle_file_upload(new_a_files, session_dirs["Stage_A"])

        with tab_b:
            b_files_list = get_file_list(session_dirs["Stage_B"])
            if b_files_list:
                for i, file_info in enumerate(b_files_list):
                    display_name = truncate_filename(file_info['name'])
                    with st.expander(f"ğŸ“„ {display_name}", expanded=False):
                        col_info, col_action = st.columns([3, 1])
                        with col_info:
                            st.write(f"**æ–‡ä»¶å:** {file_info['name']}")
                            st.write(f"**å¤§å°:** {format_file_size(file_info['size'])}")
                            st.write(f"**ä¿®æ”¹æ—¶é—´:** {format_timestamp(file_info['modified'])}")
                        with col_action:
                            delete_key = f"delete_b_{file_info['name'].replace(' ', '_').replace('.', '_')}_{session_id}"
                            if st.button("ğŸ—‘ï¸ åˆ é™¤", key=delete_key):
                                try:
                                    os.remove(file_info['path'])
                                    st.success(f"å·²åˆ é™¤: {file_info['name']}")
                                except Exception as e:
                                    st.error(f"åˆ é™¤å¤±è´¥: {e}")
            else:
                st.write("ï¼ˆæœªä¸Šä¼ ï¼‰")
            st.markdown("---")
            st.markdown("**ä¸Šä¼ æ–°æ–‡ä»¶:**")
            new_b_files = st.file_uploader("é€‰æ‹©Bæ ·é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key=f"b_uploader_tab_{session_id}")
            if new_b_files:
                handle_file_upload(new_b_files, session_dirs["Stage_B"])

        with tab_c:
            c_files_list = get_file_list(session_dirs["Stage_C"])
            if c_files_list:
                for i, file_info in enumerate(c_files_list):
                    display_name = truncate_filename(file_info['name'])
                    with st.expander(f"ğŸ“„ {display_name}", expanded=False):
                        col_info, col_action = st.columns([3, 1])
                        with col_info:
                            st.write(f"**æ–‡ä»¶å:** {file_info['name']}")
                            st.write(f"**å¤§å°:** {format_file_size(file_info['size'])}")
                            st.write(f"**ä¿®æ”¹æ—¶é—´:** {format_timestamp(file_info['modified'])}")
                        with col_action:
                            delete_key = f"delete_c_{file_info['name'].replace(' ', '_').replace('.', '_')}_{session_id}"
                            if st.button("ğŸ—‘ï¸ åˆ é™¤", key=delete_key):
                                try:
                                    os.remove(file_info['path'])
                                    st.success(f"å·²åˆ é™¤: {file_info['name']}")
                                except Exception as e:
                                    st.error(f"åˆ é™¤å¤±è´¥: {e}")
            else:
                st.write("ï¼ˆæœªä¸Šä¼ ï¼‰")
            st.markdown("---")
            st.markdown("**ä¸Šä¼ æ–°æ–‡ä»¶:**")
            new_c_files = st.file_uploader("é€‰æ‹©Cæ ·é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key=f"c_uploader_tab_{session_id}")
            if new_c_files:
                handle_file_upload(new_c_files, session_dirs["Stage_C"])
    # Render MAIN column content: uploaders and controls
    with col_main:
        # File uploads directly in col_main (no nested columns)
        col_initial, col_a, col_b, col_c = st.columns(4)
        with col_initial:
            files_initial = st.file_uploader("ç‚¹å‡»ä¸Šä¼ ç«‹é¡¹é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key="stage_initial")
            if files_initial:
                handle_file_upload(files_initial, session_dirs["Stage_Initial"])
                st.success(f"å·²ä¸Šä¼  {len(files_initial)} ä¸ªç«‹é¡¹é˜¶æ®µæ–‡ä»¶")
        with col_a:
            files_a = st.file_uploader("ç‚¹å‡»ä¸Šä¼ Aæ ·é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key="stage_a")
            if files_a:
                handle_file_upload(files_a, session_dirs["Stage_A"])
                st.success(f"å·²ä¸Šä¼  {len(files_a)} ä¸ªAæ ·é˜¶æ®µæ–‡ä»¶")
        with col_b:
            files_b = st.file_uploader("ç‚¹å‡»ä¸Šä¼ Bæ ·é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key="stage_b")
            if files_b:
                handle_file_upload(files_b, session_dirs["Stage_B"])
                st.success(f"å·²ä¸Šä¼  {len(files_b)} ä¸ªBæ ·é˜¶æ®µæ–‡ä»¶")
        with col_c:
            files_c = st.file_uploader("ç‚¹å‡»ä¸Šä¼ Cæ ·é˜¶æ®µæ–‡ä»¶", type=None, accept_multiple_files=True, key="stage_c")
            if files_c:
                handle_file_upload(files_c, session_dirs["Stage_C"])
                st.success(f"å·²ä¸Šä¼  {len(files_c)} ä¸ªCæ ·é˜¶æ®µæ–‡ä»¶")

        # Start button - only show if process hasn't started
        if not session['process_started']:
            col_buttons = st.columns([1, 1])
            with col_buttons[0]:
                if st.button("å¼€å§‹", key=f"file_completeness_start_button_{session_id}"):
                    # Start the analysis process
                    start_analysis(session_id, 'completeness')
                    st.rerun()
            with col_buttons[1]:
                if st.button("æ¼”ç¤º", key=f"file_completeness_demo_button_{session_id}"):
                    # Demo feature: copy demonstration files to current session
                    demo_base_dir = CONFIG["directories"]["apqp_files"].parent / "demonstration"
                    
                    # Copy files from demonstration APQP_files to session folders
                    demo_apqp_path = os.path.join(demo_base_dir, "APQP_files")
                    if os.path.exists(demo_apqp_path):
                        import shutil
                        for stage_folder in ["Stage_Initial", "Stage_A", "Stage_B", "Stage_C"]:
                            demo_stage_path = os.path.join(demo_apqp_path, stage_folder)
                            session_stage_path = session_dirs[stage_folder]
                            
                            if os.path.exists(demo_stage_path):
                                # Copy all files from demo stage folder to session stage folder
                                for file_name in os.listdir(demo_stage_path):
                                    demo_file_path = os.path.join(demo_stage_path, file_name)
                                    session_file_path = os.path.join(session_stage_path, file_name)
                                    
                                    if os.path.isfile(demo_file_path):
                                        shutil.copy2(demo_file_path, session_file_path)
                        
                        start_analysis(session_id, 'completeness')
                        st.success("æ¼”ç¤ºå·²å¼€å§‹ï¼æ­£åœ¨åˆ†ææ¼”ç¤ºæ–‡ä»¶...")
                        st.rerun()
                    else:
                        st.error("æ¼”ç¤ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ¼”ç¤ºæ–‡ä»¶å¤¹")
        
        # Show results if process has started
        if session['process_started']:
            st.divider()
            
            # Add a button to reset and clear history with status message
            col_reset, col_status = st.columns([1, 2])
            with col_reset:
                if st.button("é‡æ–°å¼€å§‹", key=f"file_completeness_reset_button_{session_id}"):
                    reset_user_session(session_id, 'completeness')
                    st.rerun()
            
            with col_status:
                if not session['analysis_completed']:
                    st.info("ğŸ¤– åˆ†æè¿›è¡Œä¸­...")
                else:
                    st.success("âœ… åˆ†æå®Œæˆ")
                    # Add a more prominent reset option when analysis is completed
                    st.info('ğŸ’¡ å¦‚éœ€é‡æ–°å¼€å§‹åˆ†æï¼Œè¯·ç‚¹å‡»å·¦ä¾§çš„"é‡æ–°å¼€å§‹"æŒ‰é’®')
            
            # Define stage requirements
            stage_requirements = {
                "ç«‹é¡¹é˜¶æ®µ": """1. é¡¹ç›®ç«‹é¡¹æŠ¥å‘Š
2. é¡¹ç›®å¯è¡Œæ€§åˆ†ææŠ¥å‘Š
3. é¡¹ç›®é£é™©è¯„ä¼°æŠ¥å‘Š
4. é¡¹ç›®è®¡åˆ’ä¹¦
5. é¡¹ç›®å›¢é˜Ÿç»„å»ºæ–¹æ¡ˆ
6. é¡¹ç›®é¢„ç®—æ–¹æ¡ˆ
7. é¡¹ç›®æ—¶é—´è®¡åˆ’
8. é¡¹ç›®è´¨é‡ç›®æ ‡
9. é¡¹ç›®æˆæœ¬ç›®æ ‡
10. é¡¹ç›®äº¤ä»˜ç‰©æ¸…å•""",
                
                "Aæ ·é˜¶æ®µ": """1. ç”µèŠ¯è§„æ ¼ä¹¦
2. å°ºå¯¸é“¾å…¬å·®è®¡ç®—ä¹¦
3. åˆå§‹DFMEA
4. åˆå§‹ç‰¹æ®Šç‰¹æ€§æ¸…å•
5. ä¸‰æ–°æ¸…å•
6. åˆ¶ç¨‹æ ‡å‡†
7. å¼€æ¨¡æ¸…å•
8. 3Dæ•°æ¨¡
9. 2Då›¾çº¸
10. BOMæ¸…å•
11. ä»¿çœŸæŠ¥å‘Š
12. æµ‹è¯•å¤§çº²
13. ä¸“åˆ©æŒ–æ˜æ¸…å•
14. åˆç‰ˆPFMEA
15. äº§çº¿è§„åˆ’æ–¹æ¡ˆ
16. è¿‡ç¨‹è®¾è®¡åˆå§‹æ–¹æ¡ˆ
17. äº§å“å¯åˆ¶é€ æ€§åˆ†æåŠé£é™©åº”å¯¹æŠ¥å‘Š
18. åˆå§‹è¿‡ç¨‹æµç¨‹å›¾
19. åˆå§‹è¿‡ç¨‹ç‰¹æ®Šç‰¹æ€§
20. åˆç‰ˆCP
21. åˆç‰ˆSOP
22. å·¥è‰ºéªŒè¯è®¡åˆ’
23. æ ·å“åŒ…è£…æ–¹æ¡ˆ""",
                
                "Bæ ·é˜¶æ®µ": """1. è®¾è®¡å˜æ›´å±¥å†è¡¨
2. æ›´æ–°ç”µèŠ¯è§„æ ¼ä¹¦
3. æ›´æ–°DFMEA
4. æ›´æ–°ç‰¹æ®Šç‰¹æ€§æ¸…å•
5. åˆ¶ç¨‹æ ‡å‡†
6. æ›´æ–°3Dæ•°æ¨¡
7. æ›´æ–°2Då›¾çº¸
8. å°ºå¯¸é“¾å…¬å·®è®¡ç®—ä¹¦
9. æ›´æ–°BOMæ¸…å•
10. æ›´æ–°å¼€æ¨¡æ¸…å•
11. æ›´æ–°ä¸‰æ–°æ¸…å•
12. ä»¿çœŸæŠ¥å‘Š
13. DVæµ‹è¯•æŠ¥å‘Š""",
                
                "Cæ ·é˜¶æ®µ": """1. æ›´æ–°PFMEA
2. é‡äº§äº§çº¿å¼€å‘è¿›å±•æŠ¥å‘Š
3. æ›´æ–°æ ·å“åŒ…è£…æ–¹æ¡ˆ
4. æ›´æ–°è¿‡ç¨‹æµç¨‹å›¾
5. æ›´æ–°è¿‡ç¨‹ç‰¹æ®Šç‰¹æ€§æ¸…å•
6. æ›´æ–°CP
7. æ›´æ–°SOP
8. å·¥è‰ºéªŒè¯è®¡åˆ’
9. æ ·å“å†å²é—®é¢˜æ¸…å•
10. CMKåˆ†ææŠ¥å‘Š
11. CPKåˆ†ææŠ¥å‘Š
12. å·¥ç¨‹å˜æ›´å±¥å†è¡¨
13. äº§å“å¯åˆ¶é€ æ€§åˆ†æåŠé£é™©åº”å¯¹æŠ¥å‘Š
14. è®¾å¤‡åœæœºç‡ç»Ÿè®¡è¡¨&è®¾å¤‡æ•…éšœè®°å½•è¡¨
15. å·¥è‰ºéªŒè¯æŠ¥å‘Š
16. å¤–è§‚æ ‡å‡†ä¹¦
17. PVæµ‹è¯•æŠ¥å‘Š"""
            }
            
            # Generate prompts and run analysis for each stage
            stages = [
                ("ç«‹é¡¹é˜¶æ®µ", session_dirs["Stage_Initial"]),
                ("Aæ ·é˜¶æ®µ", session_dirs["Stage_A"]),
                ("Bæ ·é˜¶æ®µ", session_dirs["Stage_B"]),
                ("Cæ ·é˜¶æ®µ", session_dirs["Stage_C"])
            ]
            
            # Dictionary to store all stage responses for Excel export
            stage_responses = {}
            
            for stage_name, stage_folder in stages:
                if os.path.exists(stage_folder):
                    if any(os.listdir(stage_folder)):
                        # Stage has files - run full LLM analysis
                        # Generate prompt for this stage
                        prompt = generate_stage_prompt(stage_name, stage_folder, stage_requirements[stage_name])
                        
                        # Save prompt to file
                        prompt_file = os.path.join(completeness_dir, f"prompt_{stage_name}.txt")
                        with open(prompt_file, "w", encoding="utf-8") as f:
                            f.write(prompt)
                        
                        # Display the prompt and response side by side
                        col_prompt, col_response = st.columns([1, 1])
                        with col_prompt:
                            st.subheader(f"{stage_name} - æç¤ºè¯:")
                            prompt_container = st.container(height=400)
                            with prompt_container:
                                with st.chat_message("user"):
                                    prompt_placeholder = st.empty()
                                    prompt_placeholder.text(prompt)
                                
                                st.chat_input(placeholder="", disabled=True, key=f"file_completeness_prompt_chat_input_{stage_name}_{session_id}")
                        
                        with col_response:
                            st.subheader(f"{stage_name} - æ£€æŸ¥ç»“æœ:")
                            response_container = st.container(height=400)
                            with response_container:
                                with st.chat_message("assistant"):
                                    response_placeholder = st.empty()
                                    
                                    # Stream the response using selected LLM
                                    response_text = ""
                                    if llm_backend in ("ollama_127", "ollama_9"):
                                        for chunk in ollama_client.chat(
                                            model=st.session_state.get(f'ollama_model_{session_id}', CONFIG["llm"]["ollama_model"]),
                                            messages=[{"role": "user", "content": prompt}],
                                            stream=True,
                                            options={
                                                "temperature": st.session_state.get(f'ollama_temperature_{session_id}', 0.7),
                                                "top_p": st.session_state.get(f'ollama_top_p_{session_id}', 0.9),
                                                "top_k": st.session_state.get(f'ollama_top_k_{session_id}', 40),
                                                "repeat_penalty": st.session_state.get(f'ollama_repeat_penalty_{session_id}', 1.1),
                                                "num_ctx": st.session_state.get(f'ollama_num_ctx_{session_id}', 40001),
                                                "num_thread": st.session_state.get(f'ollama_num_thread_{session_id}', 4),
                                                "format": "json"
                                            }
                                        ):
                                            new_text = chunk['message']['content']
                                            response_text += new_text
                                            response_placeholder.write(response_text)
                                    elif llm_backend == "openai":
                                        stream = openai.chat.completions.create(
                                            model=st.session_state.get(f'openai_model_{session_id}', CONFIG["llm"]["openai_model"]),
                                            messages=[{"role": "user", "content": prompt}],
                                            stream=True,
                                            temperature=st.session_state.get(f'openai_temperature_{session_id}', 0.7),
                                            top_p=st.session_state.get(f'openai_top_p_{session_id}', 1.0),
                                            max_tokens=st.session_state.get(f'openai_max_tokens_{session_id}', 2048),
                                            presence_penalty=st.session_state.get(f'openai_presence_penalty_{session_id}', 0.0),
                                            frequency_penalty=st.session_state.get(f'openai_frequency_penalty_{session_id}', 0.0),
                                            response_format={"type": "json_object"}
                                        )
                                        for chunk in stream:
                                            delta = chunk.choices[0].delta.content or ""
                                            response_text += delta
                                            response_placeholder.write(response_text)
                                    
                                    # Store the response for Excel export
                                    stage_responses[stage_name] = response_text
                                    
                                    st.chat_input(placeholder="", disabled=True, key=f"file_completeness_response_chat_input_{stage_name}_{session_id}")
                    else:
                        # Stage has no files - show simple message
                        st.info(f"ğŸ“ {stage_name}æ–‡ä»¶å¤¹ä¸ºç©ºï¼Œå› æ­¤è¯¥é˜¶æ®µçš„æ‰€æœ‰å¿…éœ€æ–‡ä»¶å‡ç¼ºå¤±ã€‚")
                        # Store empty response for Excel export (will be handled as "å¦" for all requirements)
                        stage_responses[stage_name] = ""
            
            # Mark analysis as completed and export Excel
            if not session['analysis_completed']:
                complete_analysis(session_id, 'completeness')
                
                # Export results to Excel after all stages are processed
                if stage_responses:
                    export_completeness_results(session_id, stage_responses, completeness_dir)


        # (Bulk operations moved earlier to avoid duplicate keys and to update UI promptly)